# 一、数据清洗是什么？

数据清洗，顾名思义就是将要用到的数据中重复、多余部分的数据进行筛选并清除；把缺失部分补充完整，并将不正确的数据纠正或者删除。最后整理成可以进一步加工、使用的数据。

注：很多做ml和dl任务拿到的数据并非可以直接使用的数据，往往需要先进行数据清洗这一步。



# 二、数据清洗想要洗掉什么？

从上面数据清洗的概念就可以大概知道数据清洗是在清洗什么了，洗掉的就是数据集中的“脏”数据。“脏数据”，即数据集中残缺、错误、重复的数据。数据清洗，旨在提高数据的质量、缩小数据统计过程中的误差值。



# 三、常见的数据清洗方法？

注：不同类型的数据异常所要用到的方法有所不同，因此我们拿到原始数据之后，需要先分析都有什么样的数据异常，然后再使用相应异常下常常采用的方法，正所谓“对症下药”，方能“药到病除”。



## 1、重复数据：

> （1）删除法



## 2、缺失值处理：

> （1）删除法：删除法是指当缺失的观测比例非常低时（如5%以内），直接删除存在缺失的观测，或者当某些变量的缺失比例非常高时（如85%以上），直接删除这些缺失的变量；
>
> （2）替换法：替换法是指用某种常数直接替换那些缺失值，例如，对连续变量而言，可以使用均值或中位数替换，对于离散变量，可以使用众数替换；
>
> （3）插补法：插补法是指根据其他非缺失的变量或观测来预测缺失值，常见的插补法有回归插补法、K近邻插补法、拉格朗日插补法等。

## 3、异常值处理：

异常值是指那些远离正常值的观测，即“不合群”观测。

**异常值检测**方法：

a、简单统计量分析：计算统计量值，常见的就是看最大最小值是否合理。

b、3 准则：是正态分布的参数，所谓3准则就算是将不落在正负 3内的值认为是异常值，应为它们发生的概率为0.3%

c、基于模型检测：首先建立一个数据模型，异常是那些同模型不能完美拟合的对象;如果模型是簇的集合，则异常是不显著属于任何簇的对象;在使用回归模型时，异常是相对远离预测值的对象

d、基于距离：通过在对象之间定义临近性度量，异常对象是那些远离其它对象的对象

e、基于聚类：基于聚类的离群点：一个对象是基于聚类的离群点，如果该对象不强属于任何簇。离群点对初始聚类的影响：如果通过聚类检测离群点，则由于离群点影响聚类，存在一个问题：结构是否有效。为了处理该问题，可以使用如下方法：对象聚类，删除离群点，对象再次聚类。



**处理异常值**常用的方法：

> （1）删除异常值----明显看出是异常且数量较少可以直接删除
> （2）不处理---如果算法对异常值不敏感则可以不处理，但如果算法对异常值敏感，则最好不要用这种方法，如基于距离计算的一些算法，包括kmeans，knn之类的。
> （3）平均值替代----损失信息小，简单高效。
> （4）视为缺失值----可以按照处理缺失值的方法来处理

# 四、数据清洗简单案例：

注：这里推荐菜鸟教程中的一个利用Pandas读取csv文件并进行数据清洗的案例，既简单，又清晰易懂。

案例学习链接：[数据清洗简单案例](https://www.runoob.com/pandas/pandas-cleaning.html)
